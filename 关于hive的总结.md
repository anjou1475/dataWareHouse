# 关于hive的总结

## 1. Hive **和数据库比较** 

Hive 和数据库除了拥有类似的查询语言，再无类似之处。 

(1）数据存储位置 

Hive 存储在 HDFS 。数据库将数据保存在块设备或者本地文件系统中。 

(2）数据更新 

Hive 中不建议对数据的改写。而数据库中的数据通常是需要经常进行修改的， 

(3）执行延迟 

Hive 执行延迟较高。数据库的执行延迟较低。当然，这个是有条件的，即数据规模较 

小，当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势。 

(4）数据规模 

Hive 支持很大规模的数据计算；数据库可以支持的数据规模较小。 

## 2. **内部表和外部表** 

(1）管理表：当我们删除一个管理表时，Hive 也会删除这个表中数据。管理表不适合 

和其他工具共享数据。 



(2）外部表：删除该表并不会删除掉原始数据，删除的是表的元数据 

## 3 .    4 **个** **By** **区别** 

(1）Sort By：分区内有序； 

(2）Order By：全局排序，只有一个 Reducer； 

(3）Distrbute By：类似 MR 中 Partition，进行分区，结合 sort by 使用。 

(4） Cluster By：当 Distribute by 和 Sorts by 字段相同时，可以使用 Cluster by 

方式。Cluster by 除了具有 Distribute by 的功能外还兼具 Sort by 的功能。但是排序只 

能是升序排序，不能指定排序规则为 ASC 或者 DESC。 

## 4.  **窗口函数** 

RANK() 排序相同时会重复，总数不会变 

DENSE_RANK() 排序相同时会重复，总数会减少 

ROW_NUMBER() 会根据顺序计算 

(1） OVER()：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的 

变而变化

(2）CURRENT ROW：当前行 

(3）n PRECEDING：往前 n 行数据 

(4） n FOLLOWING：往后 n 行数据 

(5 ） UNBOUNDED ： 起 点 ， UNBOUNDED PRECEDING 表 示 从 前 面 的 起 点 ， 

UNBOUNDED FOLLOWING 表示到后面的终点 

(6） LAG(col,n)：往前第 n 行数据 

(7）LEAD(col,n)：往后第 n 行数据 

 

(8） NTILE(n)：把有序分区中的行分发到指定数据的组中，各个组有编号，编号从 1 

开始，对于每一行，NTILE 返回此行所属的组的编号。注意：n 必须为 int 类型。 

## 5.自定义 **UDF**、**UDTF** 

在项目中是否自定义过 UDF、UDTF 函数，以及用他们处理了什么问题，及自定义步 

骤？

(1）自定义过。 

(2）用 UDF 函数解析公共字段；用 UDTF 函数解析事件字段。 

自定义 UDF：继承 UDF，重写 evaluate 方法 

自定义 UDTF：继承自 GenericUDTF，重写 3 个方法：initialize(自定义输出的列名 

和类型)，process（将结果返回 forward(result)），close 

为什么要自定义 UDF/UDTF，因为自定义函数，可以自己埋点 Log 打印日志，出错或 

者数据异常，方便调试. 

## **6. Hive** **优化** 

(**1**）**MapJoin** 

如果不指定 MapJoin 或者不符合 MapJoin 的条件，那么 Hive 解析器会将 Join 操作转 

换成 Common Join，即：在 Reduce 阶段完成 join。容易发生数据倾斜。可以用 MapJoin 

把小表全部加载到内存在 map 端进行 join，避免 reducer 处理。 

(**2**）行列过滤

列处理：在 SELECT 中，只拿需要的列，如果有，尽量使用分区过滤，少用 SELECT *。 

行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在 Where 后面， 

那么就会先全表关联，之后再过滤。 



(**3**）列式存储** 

(**4**）采用分区技术** 

(**5**）合理设置** **Map** **数** 

**（****1****）通常情况下，作业会通过** **input** **的目录产生一个或者多个** **map** **任务。** 

主要的决定因素有：input 的文件总个数，input 的文件大小，集群设置的文件块大小。 

**（****2****）是不是** **map** **数越多越好？** 

答案是否定的。如果一个任务有很多小文件（远远小于块大小 128m），则每个小文 

件也会被当做一个块，用一个 map 任务来完成，而一个 map 任务启动和初始化的时间远 

远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的 map 数是受限的。 

(**6**）小文件进行合并** 

在 Map 执行前合并小文件，减少 Map 数：CombineHiveInputFormat 具有对小文 

件进行合并的功能（系统默认的格式）。HiveInputFormat 没有对小文件合并功能。 



(**9**）开启** **map** **端** **combiner****（不影响最终业务逻辑）** 

set hive.map.aggr=true； 

(**10**）压缩（选择快的）** 

设置 map 端输出、中间结果压缩。（不完全是解决数据倾斜的问题，但是减少了 IO 

读写和网络传输，能提高很多效率） 

(**11**）开启** **JVM** **重用** 